{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.chdir('/Users/Vincent/Desktop/Python/DataCamp/Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 8, 'min_samples_leaf': 2}\n",
      "Best score is 0.7395833333333334\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "y = df['Outcome']\n",
    "X = df.drop('Outcome', axis=1)\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "tree_cv.fit(X,y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using entropy:  0.9590643274853801\n",
      "Accuracy achieved by using the gini index:  0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wbc = pd.read_csv('wbc.csv')\n",
    "y = wbc.iloc[:,1]\n",
    "X = wbc.drop(wbc.columns[[0,1,32]], axis=1)\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 'different the information criteria\n",
    "dt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "y_pred_entropy = dt_entropy.predict(X_test)\n",
    "\n",
    "dt_gini = DecisionTreeClassifier(max_depth=8, criterion='gini', random_state=1)\n",
    "dt_gini.fit(X_train, y_train)\n",
    "y_pred_gini = dt_gini.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_pred_entropy, y_test)\n",
    "accuracy_gini = accuracy_score(y_pred_gini, y_test)\n",
    "\n",
    "print('Accuracy achieved by using entropy: ', accuracy_entropy)\n",
    "print('Accuracy achieved by using the gini index: ', accuracy_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "liver = pd.read_csv('indian_liver_patient_preprocessed.csv')\n",
    "y = liver.loc[:,'Liver_disease']\n",
    "X = liver.drop(['Liver_disease'], axis=1)\n",
    "X = X.drop(X.columns[[0]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)\n",
    "\n",
    "params_dt = {\n",
    "             'max_depth': [2, 3, 4],\n",
    "             'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]\n",
    "            }\n",
    "grid_dt = GridSearchCV(estimator=tree,param_grid=params_dt,scoring='roc_auc',cv=5,n_jobs=-1)\n",
    "grid_dt.fit(X_train,y_train)\n",
    "\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = grid_dt.predict_proba(X_test)[:,1]\n",
    "test_roc_auc = roc_auc_score(y_test,y_pred_proba)\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 3.97\n",
      "Test set RMSE of dt: 4.18\n",
      "CV RMSE: 4.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "mpg = pd.read_csv('auto.csv')\n",
    "\n",
    "dummies = pd.get_dummies(mpg['origin'], columns=['Asia', 'US', 'Europe'])\n",
    "df = pd.concat([mpg,dummies], axis=1)\n",
    "df = df.drop(df[['origin']], axis=1)\n",
    "y = df.iloc[:,0]\n",
    "X = df.drop('mpg',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "\n",
    "# training error\n",
    "dt = DecisionTreeRegressor(max_depth=8,min_samples_leaf=0.13,random_state=3)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "RMSE_train = (MSE(y_train, y_pred_train))**(1/2)\n",
    "\n",
    "# test error\n",
    "y_pred = dt.predict(X_test)\n",
    "mse_dt = MSE(y_pred, y_test)\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "\n",
    "# Cross-validation error\n",
    "MSE_CV_scores = - cross_val_score(dt, X,y, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "RMSE_CV = MSE_CV_scores.mean()**(1/2)\n",
    "\n",
    "print('Train RMSE: {:.2f}'.format(RMSE_train))\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.764\n",
      "K Nearest Neighbours : 0.701\n",
      "Classification Tree : 0.730\n",
      "Voting Classifier: 0.770\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "liver = pd.read_csv('indian_liver_patient_preprocessed.csv')\n",
    "y = liver.loc[:,'Liver_disease']\n",
    "X = liver.drop(['Liver_disease'], axis=1)\n",
    "X = X.drop(X.columns[[0]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)\n",
    "\n",
    "# logistic\n",
    "lr = LogisticRegression(random_state=1)\n",
    "# knn\n",
    "knn = KNN(n_neighbors=27)\n",
    "# decisiontree\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=1)\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]\n",
    "\n",
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    "    clf.fit(X_train, y_train)    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_pred, y_test) \n",
    "   \n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))\n",
    "    \n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "vc.fit(X_train, y_train)   \n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.690, OOB accuracy: 0.706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "bc = BaggingClassifier(base_estimator=dt, \n",
    "            n_estimators=50,\n",
    "            oob_score=True,\n",
    "            random_state=1)\n",
    "bc.fit(X_train,y_train)\n",
    "\n",
    "y_pred = bc.predict(X_test)\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 51.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "bikes = pd.read_csv('bikes.csv')\n",
    "y = bikes.loc[:,'cnt']\n",
    "X = bikes.drop(['cnt'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=2)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=25, random_state=2)   \n",
    "rf.fit(X_train, y_train) \n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hr': 0.76, 'holiday': 0.0, 'workingday': 0.15, 'temp': 0.02, 'hum': 0.03, 'windspeed': 0.01, 'instant': 0.02, 'mnth': 0.0, 'yr': 0.0, 'Clear to partly cloudy': 0.0, 'Light Precipitation': 0.0, 'Misty': 0.0}\n",
      "Index(['hr', 'workingday'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# feature importances\n",
    "importances = pd.Series(data=rf.feature_importances_,index= X_train.columns)\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()\n",
    "# Print the importances per feature\n",
    "print(dict(zip(X.columns, rf.feature_importances_.round(2))))\n",
    "\n",
    "# Create a mask for features importances above the threshold\n",
    "mask = rf.feature_importances_ > 0.10\n",
    "\n",
    "# Apply the mask to the feature dataset X\n",
    "reduced_X = X.loc[:,mask]\n",
    "\n",
    "# prints out the selected column names\n",
    "print(reduced_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 4 features.\n",
      "Index(['hr', 'workingday'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    " \n",
    "# Check whether RFE results in the sae outcome\n",
    "rfe = RFE(estimator=rf, n_features_to_select=2, step=2, verbose=1)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "mask = rfe.support_\n",
    "reduced_X = X.loc[:, mask]\n",
    "\n",
    "print(reduced_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   16.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 52.088\n"
     ]
    }
   ],
   "source": [
    "params_rf = {\n",
    "    'n_estimators':[100,350,500],\n",
    "    'max_features':['log2','auto','sqrt'],\n",
    "    'min_samples_leaf':[2,10,30]\n",
    "}\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_model = grid_rf.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y = liver.loc[:,'Liver_disease']\n",
    "X = liver.drop(['Liver_disease'], axis=1)\n",
    "X = X.drop(X.columns[[0]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)\n",
    "ada.fit(X_train,y_train)\n",
    "\n",
    "# Predicted positive class probabilities\n",
    "y_pred_proba = ada.predict_proba(X_test)[:,1]\n",
    "\n",
    "# AUC\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of gb: 49.374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "y = bikes.loc[:,'cnt']\n",
    "X = bikes.drop(['cnt'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=2)\n",
    "\n",
    "gb = GradientBoostingRegressor(max_depth=4,\n",
    "                               n_estimators=200,\n",
    "                               random_state=2)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "rmse_test = mse_test**(1/2)\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of Stochastic Gradient Boosting: 50.452\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Boosting\n",
    "sgbr = GradientBoostingRegressor(max_depth=4, subsample=0.9, max_features=0.75\n",
    "                                 , n_estimators=200, random_state=2)\n",
    "sgbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgbr.predict(X_test)\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "rmse_test = mse_test**(1/2)\n",
    "print('Test set RMSE of Stochastic Gradient Boosting: {:.3f}'.format(rmse_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
